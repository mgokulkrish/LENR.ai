{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LLM Model imports\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig, AutoConfig, pipeline\n",
    "from accelerate import FullyShardedDataParallelPlugin, Accelerator\n",
    "from torch.distributed.fsdp.fully_sharded_data_parallel import FullOptimStateDictConfig, FullStateDictConfig\n",
    "\n",
    "# Vector DB\n",
    "from langchain.vectorstores import Chroma, FAISS\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "\n",
    "# Langchain\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.llms import HuggingFacePipeline\n",
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "# Generic imports\n",
    "from enum import Enum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token will not been saved to git credential helper. Pass `add_to_git_credential=True` if you want to set the git credential as well.\n",
      "Token is valid (permission: write).\n",
      "Your token has been saved to /home/rr4577/.cache/huggingface/token\n",
      "Login successful\n"
     ]
    }
   ],
   "source": [
    "from huggingface_hub import login\n",
    "\n",
    "login(\"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\") # rishavroy97\n",
    "# login(\"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\") # mgokulkrish"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameter List\n",
    "\n",
    "db_choice = \"FAISS\"\n",
    "embedding_model = \"all-MiniLM-L6-v2\"\n",
    "llm_model = \"llama2\"\n",
    "model_hyperparams = {\n",
    "    'temp': 0.1,\n",
    "    'max_tokens': 512,\n",
    "    'rep_penalty': 1.1\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Detected kernel version 4.18.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    }
   ],
   "source": [
    "# Step 1 : Accelerator\n",
    "\n",
    "fsdp_plugin = FullyShardedDataParallelPlugin(\n",
    "    state_dict_config=FullStateDictConfig(offload_to_cpu=True, rank0_only=False),\n",
    "    optim_state_dict_config=FullOptimStateDictConfig(offload_to_cpu=True, rank0_only=False),\n",
    ")\n",
    "\n",
    "accelerator = Accelerator(fsdp_plugin=fsdp_plugin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Load the Vectordb and getting it to production\n",
    "\n",
    "class DB_TYPE(Enum):\n",
    "    Chroma = \"Chroma\"\n",
    "    FAISS = \"FAISS\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_Chroma_DB():  \n",
    "    embedding = HuggingFaceEmbeddings(model_name=embedding_model)\n",
    "    db = Chroma(persist_directory=\"./chroma_db\", embedding_function=embedding)\n",
    "    return db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_FAISS_DB():\n",
    "    persist_directory = 'faiss_db/'\n",
    "    embeddings = HuggingFaceEmbeddings(model_name=embedding_model)\n",
    "    db = FAISS.load_local(persist_directory, embeddings)\n",
    "    return db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_vector_db(choice):\n",
    "    print(\"loading vector_db ....\")\n",
    "    all_dbs = [db.value for db in DB_TYPE]\n",
    "    if choice not in all_dbs:\n",
    "        raise ValueError(f\"Database {choice} is not supported\")\n",
    "    db = eval('get_' + choice + '_DB()')\n",
    "    print(f\"Successfully fetched {choice} DB\")\n",
    "    return db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading vector_db ....\n",
      "Successfully fetched FAISS DB\n"
     ]
    }
   ],
   "source": [
    "vector_db = get_vector_db(db_choice)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "quering question ....\n",
      "Document 0\n",
      "The ability of palladium cathodes to attain and maintain high loading levels, at high \n",
      "current density and for long times, is controlled by two factors: the condition of the \n",
      "electrochemical interface which allows the attainment of high deuterium activity; the defect \n",
      "density and mechanical condition of the bulk material which permits the Pd lattice to withstand \n",
      "and contain high bulk deuterium activities when these equilibrate to produce extreme pressures of\n",
      "\n",
      "\n",
      "Document 1\n",
      "\"Quasi-Plasma\"  Transport  Model in  Deuterium \n",
      "Overloaded  Palladium  Cathodes\n",
      "\n",
      "\n",
      "Document 2\n",
      "explanation of the phenomenon based on experimental apparatus designed to enhance the spectrum of information required to\n",
      "deﬁne the effect. Recently, In order to improve this aspect of this research, speciﬁc work has been carried out to investigate whether\n",
      "the excess power was produced concurrently with the emission of Radio Frequency from the active cathode. Suitable probes\n",
      "and triggering included in the RF experimental system revealed RF signal emission during electrochemical loading of palladium\n",
      "\n",
      "\n",
      "Document 3\n",
      "MATERIALS ISSUES OF LOADING DEUTERIUM INTO PALLADIUM AND \n",
      "THE ASSOCIATION WITH EXCESS HEAT PRODUCTION\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Check if the database is fetching data based on similarity\n",
    "\n",
    "print(\"quering question ....\")\n",
    "question = \"What factors controls the ability of palladium cathods to attain high loading levels?\"\n",
    "result_docs = vector_db.similarity_search(question)\n",
    "\n",
    "for i in range(len(result_docs)):\n",
    "    print(f\"Document {i}\")\n",
    "    print(result_docs[i].page_content)\n",
    "    print(f\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Prepare the model and tokenizer\n",
    "\n",
    "class LLM_MODEL_TYPE(Enum):\n",
    "    llama2 = \"meta-llama/Llama-2-7b-chat-hf\"\n",
    "    mistral = \"mistralai/Mistral-7B-Instruct-v0.1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the Model Quantization Config\n",
    "\n",
    "def get_quantization_config(load_4bit=True, compute_dtype=\"float16\", double_quant=False, quant_type=\"nf4\"):\n",
    "    # Activate 4-bit precision base model loading\n",
    "    use_4bit = load_4bit\n",
    "    \n",
    "    # Compute dtype for 4-bit base models\n",
    "    bnb_4bit_compute_dtype = compute_dtype\n",
    "    \n",
    "    # Quantization type (fp4 or nf4)\n",
    "    bnb_4bit_quant_type = quant_type\n",
    "    \n",
    "    # Activate nested quantization for 4-bit base models (double quantization)\n",
    "    use_nested_quant = False\n",
    "    \n",
    "    compute_dtype = getattr(torch, bnb_4bit_compute_dtype)\n",
    "    \n",
    "    try:\n",
    "        bnb_config = BitsAndBytesConfig(\n",
    "            load_in_4bit=use_4bit,\n",
    "            bnb_4bit_quant_type=bnb_4bit_quant_type,\n",
    "            bnb_4bit_compute_dtype=compute_dtype,\n",
    "            bnb_4bit_use_double_quant=use_nested_quant,\n",
    "        )\n",
    "        return bnb_config\n",
    "    except Error|Exception as e:\n",
    "        raise ValueError(f\"Error in parameters passed \\n {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Double quant set to true for Llama2 model\n",
    "bnb_config = get_quantization_config(double_quant=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_llama2_model():\n",
    "    model_id = LLM_MODEL_TYPE.llama2.value\n",
    "    \n",
    "    # begin initializing HF items\n",
    "    model_config = AutoConfig.from_pretrained(model_id)\n",
    "\n",
    "    model = AutoModelForCausalLM.from_pretrained(\n",
    "        model_id,\n",
    "        trust_remote_code=True,\n",
    "        config=model_config,\n",
    "        quantization_config=bnb_config,\n",
    "        device_map='auto'\n",
    "    )\n",
    "    \n",
    "    # enable evaluation mode to allow model inference\n",
    "    model.eval()\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_llama2_tokenizer():\n",
    "    model_id = LLM_MODEL_TYPE.llama2.value\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "    return tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mistral_model():\n",
    "    model_name=LLM_MODEL_TYPE.llama2.value\n",
    "    model = AutoModelForCausalLM.from_pretrained(\n",
    "        model_name,\n",
    "        quantization_config=bnb_config,\n",
    "    )\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mistral_tokenizer():\n",
    "    model_name=LLM_MODEL_TYPE.llama2.value\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_name, trust_remote_code=True)\n",
    "    tokenizer.pad_token = tokenizer.eos_token\n",
    "    tokenizer.padding_side = \"right\"\n",
    "    return tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model(choice):\n",
    "    print(\"loading Model ....\")\n",
    "    valid_models = [model.name for model in LLM_MODEL_TYPE]\n",
    "    if choice not in valid_models:\n",
    "        raise ValueError(f\"Model {choice} is not supported\")\n",
    "    model = eval('get_' + choice + '_model()')\n",
    "    device = f'cuda:{torch.cuda.current_device()}' if torch.cuda.is_available() else 'cpu'\n",
    "    print(f\"Successfully loaded {choice} Model on {device}\")\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tokenizer(choice):\n",
    "    print(\"loading Tokenizer ....\")\n",
    "    valid_models = [model.name for model in LLM_MODEL_TYPE]\n",
    "    if choice not in valid_models:\n",
    "        raise ValueError(f\"Model {choice} is not supported\")\n",
    "    model = eval('get_' + choice + '_tokenizer()')\n",
    "    device = f'cuda:{torch.cuda.current_device()}' if torch.cuda.is_available() else 'cpu'\n",
    "    print(f\"Successfully loaded {choice} Tokenizer on {device}\")\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading Model ....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 2/2 [00:07<00:00,  3.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully loaded llama2 Model on cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "model = get_model(llm_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading Tokenizer ....\n",
      "Successfully loaded llama2 Tokenizer on cuda:0\n"
     ]
    }
   ],
   "source": [
    "tokenizer = get_tokenizer(llm_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4: Create LLM Pipeline with Retrieval QA Chain\n",
    "\n",
    "def create_pipeline(model, tokenizer, task=\"text-generation\", **kwargs):\n",
    "    temperature = kwargs.get('temp') if 'temp' in kwargs else 0.1\n",
    "    max_new_tokens = kwargs.get('max_tokens') if 'max_tokens' in kwargs else 512\n",
    "    repetition_penalty = kwargs.get('rep_penalty') if 'rep_penalty' in kwargs else 1.1\n",
    "    \n",
    "    text_generation_pipeline = pipeline(\n",
    "        task = task,\n",
    "        model=model,\n",
    "        tokenizer=tokenizer,\n",
    "        temperature=temperature,  # 'randomness' of outputs, 0.0 is the min and 1.0 the max\n",
    "        max_new_tokens=max_new_tokens,  # max number of tokens to generate in the output\n",
    "        repetition_penalty=repetition_penalty  # without this output begins repeating\n",
    "    )\n",
    "    \n",
    "    return text_generation_pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_generation_pipeline = create_pipeline(\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    task=\"text-generation\",\n",
    "    kwargs=model_hyperparams\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_prompt_template():\n",
    "    template = \"\"\"Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer. Keep the answer as concise as possible. \n",
    "    {context}\n",
    "    Question: {question}\n",
    "    Helpful Answer:\"\"\"\n",
    "    \n",
    "    return template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_retrieval_chain(pipeline, vector_db):\n",
    "    \n",
    "    template = create_prompt_template()\n",
    "    chain_prompt = PromptTemplate.from_template(template)\n",
    "    llm = llm = HuggingFacePipeline(pipeline=pipeline)\n",
    "    retriever = vector_db.as_retriever()\n",
    "    \n",
    "    chain = RetrievalQA.from_chain_type(\n",
    "        llm,\n",
    "        retriever=retriever,\n",
    "        return_source_documents=True,\n",
    "        chain_type_kwargs={\"prompt\": QA_CHAIN_PROMPT}\n",
    "    )\n",
    "    \n",
    "    return chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "retrieval_chain = create_retrieval_chain(\n",
    "    pipeline=text_generation_pipeline,\n",
    "    vector_db=vector_db\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'query': 'What factors controls the ability of palladium cathods to attain high loading levels?',\n",
       " 'result': ' The ability of palladium cathodes to attain and maintain high loading levels is controlled by two factors: the condition of the electrochemical interface and the defect density and mechanical condition of the bulk material.',\n",
       " 'source_documents': [Document(page_content='The ability of palladium cathodes to attain and maintain high loading levels, at high \\ncurrent density and for long times, is controlled by two factors: the condition of the \\nelectrochemical interface which allows the attainment of high deuterium activity; the defect \\ndensity and mechanical condition of the bulk material which permits the Pd lattice to withstand \\nand contain high bulk deuterium activities when these equilibrate to produce extreme pressures of'),\n",
       "  Document(page_content='\"Quasi-Plasma\"  Transport  Model in  Deuterium \\nOverloaded  Palladium  Cathodes'),\n",
       "  Document(page_content='explanation of the phenomenon based on experimental apparatus designed to enhance the spectrum of information required to\\ndeﬁne the effect. Recently, In order to improve this aspect of this research, speciﬁc work has been carried out to investigate whether\\nthe excess power was produced concurrently with the emission of Radio Frequency from the active cathode. Suitable probes\\nand triggering included in the RF experimental system revealed RF signal emission during electrochemical loading of palladium'),\n",
       "  Document(page_content='MATERIALS ISSUES OF LOADING DEUTERIUM INTO PALLADIUM AND \\nTHE ASSOCIATION WITH EXCESS HEAT PRODUCTION')]}"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Approach 1: Use Retrieval Chain from LangChain\n",
    "\n",
    "question = \"What factors controls the ability of palladium cathods to attain high loading levels?\"\n",
    "result = retrieval_chain({\"query\": question})\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"<s> [INST] What factors controls the ability of palladium cathods to attain high loading levels given below context?\\nThe ability of palladium cathodes to attain and maintain high loading levels, at high \\ncurrent density and for long times, is controlled by two factors: the condition of the \\nelectrochemical interface which allows the attainment of high deuterium activity; the defect \\ndensity and mechanical condition of the bulk material which permits the Pd lattice to withstand \\nand contain high bulk deuterium activities when these equilibrate to produce extreme pressures of \\ndeuterium gas inside closed incipient voids[/INST]  The ability of palladium cathodes to attain and maintain high loading levels at high current densities and for long times is controlled by two main factors:\\n\\n1. Electrochemical interface conditions: The condition of the electrochemical interface between the palladium cathode and the electrolyte solution plays a crucial role in determining the high deuterium activity of the cathode. Factors such as the electrolyte composition, pH, and ionic strength can affect the stability and activity of the cathode. For example, a more stable and active cathode can be achieved by using a more stable and conductive electrolyte, such as a solution with a higher ionic strength.\\n2. Defect density and mechanical condition of the bulk material: The defect density and mechanical condition of the bulk palladium material also play a significant role in determining the cathode's ability to withstand and contain high bulk deuterium activities. The defect density refers to the number of defects per unit volume of the material, which can affect the material's ability to accommodate deuterium gas. A higher defect density can lead to a higher deuterium activity, but it can also increase the likelihood of void formation and degradation of the cathode. The mechanical condition of the bulk material, such as its grain size, shape, and distribution, can also affect its ability to withstand high deuterium activities. For example, a cathode with a more uniform grain size and distribution may be more resistant to void formation and degradation than one with a more irregular grain structure.\\n\\nIn summary, the ability of palladium cathodes to attain and maintain high loading levels at high current densities and for long times is controlled by the condition of the electrochemical interface and the defect density and mechanical condition of the bulk material. By optimizing these factors, it is possible to achieve high deuterium activity and stable operation of the cathode.</s>\"]\n"
     ]
    }
   ],
   "source": [
    "# Approach 2: Manually fetch similar chunks from vector db\n",
    "\n",
    "question = \"What factors controls the ability of palladium cathods to attain high loading levels?\"\n",
    "result_docs = vector_db.similarity_search(question)\n",
    "\n",
    "# inputs_not_chat = tokenizer.encode_plus(\n",
    "#     \"\"\"[INST] \"\"\" + question + \"\"\" Use the following context to answer: \"\"\" + result_docs[i].page_content + \"\"\"[/INST]\"\"\",\n",
    "#     return_tensors=\"pt\"\n",
    "# )['input_ids'].to('cuda\n",
    "\n",
    "inputs_not_chat = tokenizer.encode_plus(\"\"\"[INST] What factors controls the ability of palladium cathods to attain high loading levels given below context?\n",
    "The ability of palladium cathodes to attain and maintain high loading levels, at high \n",
    "current density and for long times, is controlled by two factors: the condition of the \n",
    "electrochemical interface which allows the attainment of high deuterium activity; the defect \n",
    "density and mechanical condition of the bulk material which permits the Pd lattice to withstand \n",
    "and contain high bulk deuterium activities when these equilibrate to produce extreme pressures of \n",
    "deuterium gas inside closed incipient voids[/INST]\"\"\", return_tensors=\"pt\")['input_ids'].to('cuda')\n",
    "\n",
    "generated_ids = model.generate(inputs_not_chat, \n",
    "                               max_new_tokens=1000, \n",
    "                               do_sample=True)\n",
    "decoded = tokenizer.batch_decode(generated_ids)\n",
    "print(decoded)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "my_env",
   "language": "python",
   "name": "my_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
